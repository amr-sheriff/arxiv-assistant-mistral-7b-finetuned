{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **ArXiv Assistant Project - Dataset Preparation**\n",
    "\n",
    "This notebook focuses on processing and preparing the arXiv dataset for use in the ArXiv Assistant project. It demonstrates the process of accessing arXiv papers from a Google Cloud Storage bucket, processing them into text chunks, and storing the resulting dataset on Hugging Face.\n",
    "\n",
    "The notebook is designed to handle large-scale data processing efficiently, utilizing multiprocessing and cloud storage integration. It serves as an intermediate step in creating a high-quality dataset for training and fine-tuning language models on arXiv content.\n",
    "\n",
    "The Notebook includes the following key components:\n",
    "\n",
    "1. **Setup and Configuration**:\n",
    "   - Imports necessary libraries including google-cloud-storage, llama-index, and various data processing tools.\n",
    "   - Sets up authentication for Google Cloud and Hugging Face.\n",
    "   - Configures environment variables and paths.\n",
    "\n",
    "2. **Google Cloud Storage Integration**:\n",
    "   - Functions to list and access files in the specified GCS bucket.\n",
    "   - Exploration of the arXiv PDF files stored in the bucket.\n",
    "\n",
    "3. **Data Processing Script Execution**:\n",
    "   - Runs a Python script (`process_arxiv_data.py`) to process the arXiv PDFs.\n",
    "   - Handles chunking of text, potentially using embeddings for semantic chunking.\n",
    "   - Processes multiple months of arXiv papers (e.g., from 2209 to 2403).\n",
    "\n",
    "4. **Dataset Creation and Upload**:\n",
    "   - Creates a dataset from the processed chunks.\n",
    "   - Uploads the resulting dataset to Hugging Face Datasets.\n",
    "\n",
    "5. **Multiprocessing Utilization**:\n",
    "   - Leverages multiprocessing to efficiently handle the large volume of data.\n",
    "\n",
    "6. **Customization and Configuration**:\n",
    "   - Allows for customization of processing parameters such as chunk size, number of files to process, and specific arXiv folders to include.\n",
    "\n",
    "This notebook serves as a vital tool in the data preparation pipeline for the ArXiv Assistant project, enabling the creation of a large, well-structured dataset of arXiv papers for further use in model training and fine-tuning.\n",
    "\n",
    "Author: Amr Sherif  \n",
    "Created Date: 2024-06-13  \n",
    "Updated Date: 2024-09-30  \n",
    "Version: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1716645850882,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "wu_BOdvBCUxB"
   },
   "source": [
    "from baseline.helpers import set_css\n",
    "\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 133879,
     "status": "ok",
     "timestamp": 1716645986057,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "kU6K_WvGaiMs",
    "outputId": "e0b7dbc9-a35a-430f-8d18-bc8f4894f6f9"
   },
   "source": [
    "!pip install --upgrade google-cloud-storage\n",
    "!pip install llama-index\n",
    "!pip install llama-index-embeddings-huggingface llama_index datasets PyMuPDF huggingface_hub transformers llama-index-embeddings-instructor\n",
    "! pip install sentence-transformers\n",
    "! pip install llama-index-embeddings-langchain\n",
    "! pip install langchain langchain-community langchain-core\n",
    "!pip install python-dotenv\n",
    "!pip install llama-index-readers-gcs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 10196,
     "status": "ok",
     "timestamp": 1716649575752,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "9zZUfIqcCl_S",
    "outputId": "90466961-f07c-4317-95d3-2a7275cb7945"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1716649578296,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "Phqu_nJtCmsB",
    "outputId": "e066fd6f-f8be-41b7-d095-0f40e8a8a80a"
   },
   "source": "%cd \"DRIVE_PATH\"",
   "outputs": []
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1716406189800,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "jw0kWKfo2kT9",
    "outputId": "54bd4854-3ca2-4b10-9d33-fa8bd994c719"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1716649581985,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "f0HF-BgxCrcK",
    "outputId": "e9321dec-2bf6-4682-c0d9-76d1a03111c2"
   },
   "source": "%ls",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 1627,
     "status": "ok",
     "timestamp": 1716649584722,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "x92LgA34Z4O4",
    "outputId": "b467912a-9028-4565-9234-f85bf6f9bc08"
   },
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ['hf'] = userdata.get('hf')\n",
    "service_account_key_path = userdata.get('service_account_key_path')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnyZl5nxlFoh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716688045069,
     "user_tz": -240,
     "elapsed": 507,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     }
    },
    "outputId": "8932a260-c30d-4c6b-ef49-088f6d6a105b"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### List and explore files in the bucket "
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1716649591894,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "krkqwAMnvL7s",
    "outputId": "87b7d143-ca2f-4fd3-ff28-567598c04200"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "bucket_name = \"arxiv-dataset\"\n",
    "prefix = \"arxiv/arxiv/pdf\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def list_files_in_bucket(bucket_name, prefix, service_account_key_path):\n",
    "    client = storage.Client.from_service_account_json(service_account_key_path)\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for page in blobs.pages:\n",
    "        yield from [blob.name for blob in page]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "a = list_files_in_bucket(bucket_name, prefix, service_account_key_path)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i, file in enumerate(list_files_in_bucket(bucket_name, prefix, service_account_key_path)):\n",
    "  print(i)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Process arXiv data into text chunks and store them in a dataset on Hugging Face Datasets"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4131005,
     "status": "ok",
     "timestamp": 1716653727495,
     "user": {
      "displayName": "Amr Achraf",
      "userId": "01741171265289641694"
     },
     "user_tz": -240
    },
    "id": "_9gGRWJeSz-h",
    "outputId": "94b13611-dfbe-45d3-8b1b-9e2350a3adf1"
   },
   "source": [
    "!python process_arxiv_data.py --bucket_name $bucket_name --prefix $prefix --folders 2403 2402 2401 2312 2311 2310 2309 2308 2307 \\\n",
    "2306 2305 2304 2303 2302 2301 2212 2211 2210 2209  \\\n",
    " --service_account_key_path $service_account_key_path \\\n",
    " --model_name \"WhereIsAI/UAE-Large-V1\" --hf_username \"amrachraf\" \\\n",
    " --hf_dataset_name \"arXiv-full-text-chunked\" --chunk_size_gb 0.1 \\\n",
    " --local_path \"TEMP_DIR_PATH\" \\\n",
    " --base_chunk_count 4 --num_files_limit 200 --max_files 400 --use_folder_limit True"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "authorship_tag": "ABX9TyNT+mwm/TBtgQZG2unoaBbQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
